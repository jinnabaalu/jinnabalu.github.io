<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Stories by Jinna Baalu on Medium]]></title>
        <description><![CDATA[Stories by Jinna Baalu on Medium]]></description>
        <link>https://medium.com/@jinnabaalu?source=rss-5c894fbb59cd------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/1*-_pBnW_FvOEYOeqovjiHUw.jpeg</url>
            <title>Stories by Jinna Baalu on Medium</title>
            <link>https://medium.com/@jinnabaalu?source=rss-5c894fbb59cd------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Tue, 06 Aug 2024 17:34:40 GMT</lastBuildDate>
        <atom:link href="https://medium.com/@jinnabaalu/feed" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Running Verdaccio a Self Hosted Private NPM with Docker]]></title>
            <link>https://jinnabaalu.medium.com/running-verdaccio-a-self-hosted-private-npm-with-docker-8506953ac4a5?source=rss-5c894fbb59cd------2</link>
            <guid isPermaLink="false">https://medium.com/p/8506953ac4a5</guid>
            <category><![CDATA[verdaccio]]></category>
            <category><![CDATA[npm]]></category>
            <category><![CDATA[docker]]></category>
            <category><![CDATA[private-npm-packages]]></category>
            <dc:creator><![CDATA[Jinna Baalu]]></dc:creator>
            <pubDate>Wed, 13 Dec 2023 21:18:40 GMT</pubDate>
            <atom:updated>2024-07-21T06:30:22.485Z</atom:updated>
            <content:encoded><![CDATA[<p>Verdaccio is a lightweight private npm registry that can be run locally.</p><h3>Clone the repo</h3><p>I created a repo with the docker-compose file for running the application in the docker container.</p><p><strong>Repo</strong>: <a href="https://github.com/ContainerTalks/verdaccio-docker-compose">verdaccio-docker-compose</a></p><h3>Run the application:</h3><p>Open a terminal, navigate to the directory containing the docker-compose.yml file, and run the following command:</p><pre>cd verdaccio-docker-compose/<br>docker-compose up  -d</pre><p>Verdaccio will be accessible at <a href="http://localhost:4873/">http://localhost:4873</a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*NVpMStb66mod2BY4HNMFFg.jpeg" /></figure><h3>How to use the npm package manager</h3><p>Get into the container</p><pre>docker exec  -it  verdaccio  sh</pre><p>To publish your first package just:</p><ol><li>Create user</li></ol><pre>$ docker exec  -it  verdaccio  sh # This command will take you into the container<br><br>$ npm adduser  --registry  http://localhost:4873/<br>npm notice Log in on http://localhost:4873/<br>Username: balu<br>Email: (this IS public) jinna.baalu@gmail.com<br><br>Logged in on http://localhost:4873/.</pre><ol><li>Go to the project to publish</li></ol><pre>mkdir nodejs-app<br>cd my-nodejs-app<br>echo &quot;console.log(&#39;Hello, World!&#39;);&quot; &gt; app.js<br>npm init -y<br>node app.js</pre><pre>npm login  --registry  <a href="http://localhost:4873/">http://localhost:4873/</a><br>npm publish  --registry  <a href="http://localhost:4873/">http://localhost:4873/</a></pre><p>Go To <a href="http://localhost:4873/">http://localhost:4873</a> and refresh you will see your package available</p><h3>Stop the application:</h3><p>To stop the running containers, use the following command:</p><pre>docker-compose down</pre><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8506953ac4a5" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Caddy HTTP to HTTPS Redirections]]></title>
            <link>https://jinnabaalu.medium.com/caddy-http-to-https-redirections-7321bdce0aa8?source=rss-5c894fbb59cd------2</link>
            <guid isPermaLink="false">https://medium.com/p/7321bdce0aa8</guid>
            <category><![CDATA[free-ssl-certificate]]></category>
            <category><![CDATA[caddy]]></category>
            <category><![CDATA[https]]></category>
            <category><![CDATA[openssl]]></category>
            <category><![CDATA[docker]]></category>
            <dc:creator><![CDATA[Jinna Baalu]]></dc:creator>
            <pubDate>Sat, 18 Jun 2022 19:42:56 GMT</pubDate>
            <atom:updated>2022-06-18T19:42:56.747Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Ubzjw9fMPvdkXIVeyQ9_DA.png" /><figcaption>caddy redirections</figcaption></figure><p>This article helps you understand the caddy configuration for HTTP to HTTPS redirection in details configuration.</p><h3>Caddy Modern Defaults</h3><p>“Caddy is the first and only web server to use HTTPS automatically and by default.”</p><p>Caddy provides the automatic redirection to https, and provisions TLS certificates for all the domains, associated with the websites in the Caddyfile configuration, keeping them renewed for free for a lifetime.</p><ul><li>No downtime</li><li>Zero lines of configuration needed</li><li>No other tools like Open SSL certification renewal are needed in NGINX comparatively</li><li>It acts as a web server and serves the website on https by default</li></ul><p>Caddy serves public DNS names over HTTPS using certificates from a public ACME CA such as <a href="https://letsencrypt.org/">Let’s Encrypt</a> or <a href="https://zerossl.com/">ZeroSSL</a></p><h3>Redirection Detail</h3><p>Caddy is schema-agnostic with the following we can achieve HTTP to https by default with the following</p><h3>Redirect all HTTP requests to HTTPS with a 301 redirect</h3><p>Caddy will run a 301 Redirect listening on HTTP and serve the actual site on HTTPS, but not www.</p><pre>example.com {<br>    ......<br>    ....<br>}</pre><h3>Manual Redirection</h3><p>Manual definition of the HTTP and https will do the job in two ways</p><ol><li>Blanket Redirect</li><li>Subdomain Redirect</li><li>Schema Check Redirect</li></ol><h3>1. Blanket</h3><p>`redir`, for the entire HTTP version of the site</p><pre><a href="http://example.com">http://example.com</a> {<br>  redir <a href="https://{host}{uri}">https://{host}{uri}</a> permanent<br>}</pre><pre>https://example.com {<br>    .......<br>    ....<br>}</pre><h3>2. Subdomain redirect</h3><pre><a href="http://www.example.com">www.example.com</a> {  <br>  redir <a href="https://example.com{uri}">https://example.com{uri}</a> permanent<br>}</pre><pre>http://www.example.com {<br>  redir <a href="https://example.com{uri}">https://example.com{uri}</a> permanent<br>}</pre><pre>https://www.example.com {<br>  redir <a href="https://example.com{uri}">https://example.com{uri}</a> permanent<br>}</pre><pre>https://example.com {<br>    .......<br>    ....<br>}</pre><h3>3. Schema Check Redirect</h3><p>redir, check for HTTP scheme, and redirect</p><pre><a href="http://example.com,">http://example.com,</a> <a href="https://example.com">https://example.com</a> {<br>  redir {<br>    if {scheme} is http <a href="https://{host}{uri}">https://{host}{uri}</a><br>  }<br>  .....<br>  ....<br>}</pre><p>More details on caddy configuration and example configurations on my <a href="https://github.com/JinnaBalu/docker-caddy">github repo</a> is available.</p><p>Reference :</p><p><a href="https://github.com/JinnaBalu/docker-caddy">Docker Caddy Conf</a></p><p><a href="https://caddyserver.com/docs/automatic-https">Automatic Redirect in Caddy</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=7321bdce0aa8" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How to reduce AWS EBS cost by 20%]]></title>
            <link>https://jinnabaalu.medium.com/how-to-reduce-aws-ebs-cost-by-20-991d904461b3?source=rss-5c894fbb59cd------2</link>
            <guid isPermaLink="false">https://medium.com/p/991d904461b3</guid>
            <category><![CDATA[aws-billing]]></category>
            <category><![CDATA[aws]]></category>
            <category><![CDATA[aws-cost-optimization]]></category>
            <category><![CDATA[ebs-volume]]></category>
            <dc:creator><![CDATA[Jinna Baalu]]></dc:creator>
            <pubDate>Sat, 21 May 2022 18:42:12 GMT</pubDate>
            <atom:updated>2022-05-21T18:42:12.940Z</atom:updated>
            <content:encoded><![CDATA[<h4>Low risk, high impact on billing</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*paHD6vRtYWg1aH04zvgPpw.png" /></figure><p>I think you will agree with me, that reducing the AWS ebs price by 20%, is the low-risk activity of changing the EBS volume type. I found this interesting and easy when I implemented it for my clients.</p><p>This no-nonsense guide will help you change ebs volume type from gp2 to gp3.</p><p><strong>What are gp2 and gp3 volume types?</strong><br>AWS announced the availability of gp3, the next-generation general purpose SSD volumes for Amazon Elastic Block Store that enable customers to provision performance independent of storage capacity and provides up to 20% lower price-point per GB than existing gp2 volumes.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/774/1*cPWXSE3Pm6nTD2jXwir__g.png" /><figcaption>Throughput conf for gp3</figcaption></figure><p>Here is the baseline IOPS difference between gp2(~3 IOPS/GB) and gp3(default 3000IOPS)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Ct7t55sY673dEsC-.png" /></figure><p>The audience for this story is, who have EBS gp2 type created long back, still not upgraded to a higher version, you continue to read the guide if you are still on gp2. if you are already on gp3 this is no more related to you.</p><h3>How to change volume type from gp2 to gp3?</h3><p>In order to change the volume type, follow these simple steps:</p><ol><li>Login to your AWS console</li><li>Choose “EC2” from the services list</li><li>Click on “Volumes” under the ELASTIC BLOCK STORE menu (on the left)</li><li>Choose the volume that you want to resize, and right-click on “Modify Volume”</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*b38GqAFFyZ6LR1IA.png" /></figure><ol><li>You’ll see an options window like this one:</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*MdDUeEbf0Fa3-Rt8.png" /></figure><ol><li>Change Volume type: “General Purpose SSD(gp3)”</li><li>Click on Modify</li></ol><h3>Impact on production</h3><p>No worries if you have few TBs of capacities, when we have larger volumes capacities we see the warning.</p><p>Here is the story.</p><p>The confirmation dialog warns that “it may take some time for performance changes to take effect.” However, it seemed fast for me (for an admittedly small 8GB volume). The EC2 console’s Volumes listing showed gp3 within seconds, though the volume’s state showed “in-use — optimizing (..%)” for about 5 minutes.</p><p>IOPS performance improves within seconds we can use <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/benchmark_procedures.html">benchmarking tests with fio</a> on the volume during the change.</p><p>One thing to be careful of is the rollback strategy for your change. If you reach the <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_ModifyVolume.html">“maximum volume modification rate per volume limit”,</a> you’ll have to wait at least six hours before changing the volume type again. For me, this meant I could only change the volume type once so any rollback would be delayed for six hours!</p><h3>Conclusion</h3><p>As you saw in the guide, changing volume type will affect your billing with low risk. Let’s pay less for more IOPS. Now you have everything you need to get started with.</p><p>Before you start on implementation, make sure to leave a quick comment to let me know what you think of ‘How to reduce AWS EBS cost by 20% with gp3’</p><h4>Ref:</h4><p><a href="https://aws.amazon.com/about-aws/whats-new/2020/12/introducing-new-amazon-ebs-general-purpose-volumes-gp3/"><em>https://aws.amazon.com/about-aws/whats-new/2020/12/introducing-new-amazon-ebs-general-purpose-volumes-gp3/</em></a> <a href="https://dzone.com/content/3234233/edit.html#"><em>x</em></a></p><p><a href="https://aws.amazon.com/ebs/general-purpose/#:~:text=gp3%20offers%20SSD%2Dperformance%20at,improving%20performance%20and%20reducing%20costs."><em>https://aws.amazon.com/ebs/general-purpose/#:~:text=gp3%20offers%20SSD%2Dperformance%20at,improving%20performance%20and%20reducing%20costs.</em></a> <a href="https://dzone.com/content/3234233/edit.html#"><em>x</em></a></p><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html?icmpid=docs_ec2_console"><em>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html?icmpid=docs_ec2_console</em></a> <a href="https://dzone.com/content/3234233/edit.html#"><em>x</em></a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=991d904461b3" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Healthy Kafka Cluster — Zero Under Replicated Partition]]></title>
            <link>https://jinnabaalu.medium.com/healthy-kafka-cluster-zero-under-replicated-partition-37409486fc4c?source=rss-5c894fbb59cd------2</link>
            <guid isPermaLink="false">https://medium.com/p/37409486fc4c</guid>
            <category><![CDATA[zookeeper]]></category>
            <category><![CDATA[containers]]></category>
            <category><![CDATA[health]]></category>
            <category><![CDATA[kafka]]></category>
            <category><![CDATA[restart]]></category>
            <dc:creator><![CDATA[Jinna Baalu]]></dc:creator>
            <pubDate>Sun, 20 Mar 2022 17:44:19 GMT</pubDate>
            <atom:updated>2022-03-20T17:52:27.001Z</atom:updated>
            <content:encoded><![CDATA[<h3>Healthy Kafka Cluster — Zero Under Replicated Partition</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1004/1*b-b3xhw-7SMTozSS683T1A.png" /><figcaption>Healthy Kafka Cluster</figcaption></figure><h4>Get the under-replicated-partitions</h4><pre>docker run --net=host --rm confluentinc/cp-kafka:4.0.0 kafka-topics --zookeeper 192.31.1.1:22181  --describe --under-replicated-partitions</pre><p><strong>Output</strong></p><pre>Topic: country	 Partition: 0    Leader: 1   Replicas: 1,2   Isr: 1<br>Topic: geodata 	 Partition: 0    Leader: 1   Replicas: 1,2   Isr: 1<br>Topic: workspace Partition: 0    Leader: 1   Replicas: 1,2   Isr: 1</pre><p>There are three topics that have the issue with replication factor i.e, cluster is not healthy. When the above query gives no output then the cluster is healthy. Reassignment of the partitions is required to make it healthy.</p><h4>If you have topics that have replication set to one? If the cluster size is higher, then reassignment needs to be considered to maintain the high availability of the topic for consumers, when a topic containing broker is restarting, then the topic goes offline.</h4><p>To know in detail about individual topics run the describe topic command.</p><pre>docker run --net=host --rm confluentinc/cp-kafka:4.0.0 kafka-topics --zookeeper 192.31.1.1:22181 --describe --topic country</pre><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=37409486fc4c" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Identify the Active Controller In Kafka]]></title>
            <link>https://jinnabaalu.medium.com/identify-the-active-controller-in-kafka-cd43ab039367?source=rss-5c894fbb59cd------2</link>
            <guid isPermaLink="false">https://medium.com/p/cd43ab039367</guid>
            <category><![CDATA[kafka]]></category>
            <category><![CDATA[containers]]></category>
            <category><![CDATA[docker]]></category>
            <category><![CDATA[zookeeper]]></category>
            <dc:creator><![CDATA[Jinna Baalu]]></dc:creator>
            <pubDate>Sun, 20 Mar 2022 16:09:40 GMT</pubDate>
            <atom:updated>2022-03-20T16:10:22.374Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1004/1*-f1Zb-R3ZFdK0oRH5TI5hw.png" /><figcaption>Kafka Active Controller</figcaption></figure><h3>What is a Controller?</h3><p>The controller is one of the Kafka brokers, usually behaves like a normal broker, and has a controlling capability of managing partition state and replicas and reassignment of the partition.</p><h3>How to get the currently active controller?</h3><p>Zookeeper is the storage of the Kafka cluster, who elects the controller node either at the beginning of the cluster setup or when the controller node crashes. Here is the command to get the controller</p><ul><li>Shell command when installed on the host</li></ul><pre>zookeeper-shell 192.168.1.1:22181 get /controller</pre><ul><li>When we are dealing with the docker container we can execute the above command in interactive mode as follows</li></ul><pre># Connect to Zookeeper<br>docker run --net=host --rm confluentinc/cp-kafka:4.0.0 zookeeper-shell 192.168.1.1:22181</pre><pre># Get the Controller<br>docker run --net=host --rm confluentinc/cp-kafka:4.0.0 zookeeper-shell 192.168.1.1:22181 get /controller</pre><blockquote><em>Note: </em><em>192.168.1.1 is the zookeeper IP</em></blockquote><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=cd43ab039367" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Docker Volumes — Persistence]]></title>
            <link>https://jinnabaalu.medium.com/docker-volumes-persistence-913427f52315?source=rss-5c894fbb59cd------2</link>
            <guid isPermaLink="false">https://medium.com/p/913427f52315</guid>
            <category><![CDATA[docker-volume]]></category>
            <category><![CDATA[docker-compose]]></category>
            <category><![CDATA[docker]]></category>
            <dc:creator><![CDATA[Jinna Baalu]]></dc:creator>
            <pubDate>Sat, 26 Dec 2020 00:00:00 GMT</pubDate>
            <atom:updated>2022-02-02T10:00:53.331Z</atom:updated>
            <content:encoded><![CDATA[<h3>Docker Volume Persistence</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1004/0*yTokqsdFI0aIIyYF.png" /></figure><p>The container uses and generates data folders that are available for the container but not to the host machine. When the container gets restarted or crashed the data generated inside is deleted permanently. Docker volume is a process of saving the data to the host machine from the container.</p><h3>Docker Volume COPY | Docker data one time copy</h3><p>Get the folder copied from container to host machine, this option useful for one-time copy, but not recommended for the databases which need the stateful behavior. Using docker cp we can copy the docker container volume to the host machine.</p><p>example:</p><blockquote><em>NOTE: The issue with the above approach is, it will not persists the volume or file or dir, as you remove the container it will be lost. This is not recommended for volume persistency dynamically.</em></blockquote><h3>Volume Mounting | Docker Volume</h3><p>Docker volume is a process of mounting the container volume to the host directory. This can be done in three ways.</p><ol><li>Anonymous Volumes</li><li>Named Volumes</li><li>Named Bind Volumes Or Host Volumes</li></ol><h4>1. Anonymous Volumes</h4><p>The location of the data mounted is managed by docker. It is very difficult to refer to the same volume. We can identify the volumes used by containers by using container inspection. To create an anonymous docker volume run</p><h4>2. Named Volumes</h4><p>Named volumes are defined by the user but the location of the data is managed by docker. Referring to named volumes is very easy compared to anonymous volumes.</p><p>We can do this in two ways creating a docker volume and referring to it while running the container with the docker run command.</p><p>We can achieve both above commands within one docker-compose.yml</p><blockquote><em>Note : Deleting the named volumes will delete the data as the data location is managed by docker.</em></blockquote><h4>3. Named Bind Volumes Or Host Volumes</h4><p>Named volumes binding or mounting to the custom directory path of the host machine. Docker volume location is defined by the user.</p><p>Volumes help save data across restarts of your docker containers. If you need to use a volume, consider the difference between the various kinds before starting development.</p><p><em>Originally published at </em><a href="https://jinnabalu.tech/Docker-volume/"><em>https://jinnabalu.tech</em></a><em> on December 26, 2020.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=913427f52315" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Elasticsearch Disk Space is too low]]></title>
            <link>https://jinnabaalu.medium.com/elasticsearch-disk-space-is-too-low-2b7049a13272?source=rss-5c894fbb59cd------2</link>
            <guid isPermaLink="false">https://medium.com/p/2b7049a13272</guid>
            <category><![CDATA[elasticsearch]]></category>
            <category><![CDATA[disk-space]]></category>
            <category><![CDATA[forbidden]]></category>
            <dc:creator><![CDATA[Jinna Baalu]]></dc:creator>
            <pubDate>Mon, 02 Nov 2020 00:00:00 GMT</pubDate>
            <atom:updated>2021-05-28T05:34:00.159Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1004/0*maYoptyX41ff73aF.png" /></figure><p><em>Fix the FORBIDDEN Read-Only / Allow Delete Error for Elasticsearch API Requests</em></p><p>Elasticsearch considers the available disk space on a node before deciding whether to allocate new shards to that node or to actively relocate shards away from that node.</p><p>Elasticsearch reads the disk space, makes all the indices into <em>READ ONLY</em> when the “Cluster Settings” are default and reaches the watermark levels. We can disable this by updating the ` disk allocation decider` as follows</p><p>We can customize the watermark level default values to the required, here is the default values</p><ul><li>cluster.routing.allocation.disk.watermark.low: (Default 85%)</li><li>cluster.routing.allocation.disk.watermark.high: (Default 90%)</li><li>cluster.routing.allocation.disk.watermark.flood_stage: (Default 95%)</li></ul><p>To know more about the disk allocation <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/disk-allocator.html">read here</a></p><h3>Priority #1</h3><p>In Production Elasticsearch Cluster deleting duplicates data or updating any of the above defaults is bad practice as we are in hurry to resolve the issue on the fly. Deleting any data decision takes an ample amount of time. Take the action of increasing the disk space before the cluster goes into <em>READ ONLY</em> node. Temporarily update threshold_enabled value to false and increase the disk space.</p><blockquote><em>For monitoring or staging servers we can go for the below priorities. Don’t read Priority #2 and Priority #3, if you are doing it on production server, we make mistakes, deleting any production index cost more, be conscious doing any of the deleting activities.</em></blockquote><p>Recommended only for staging/pre-production/monitoring/</p><h3>Priority #2</h3><p>Delete the unwanted indices or unwanted data from the disk</p><h3>Priority #3</h3><p>Update the cluster.routing.allocation.disk. default values to set them according to the requirement, this is recommended on dev machine. By setting the cluster.routing.allocation.disk.watermark levels we can re-enable the index to writable.</p><p>Watermark levels can be set in two ways, but we can’t mix both</p><ul><li>Absolute byte values</li><li>Percentage values</li></ul><h4>Absolute Bytes</h4><pre>1 2 3 4 5 6 7 8 9 10 11 12</pre><pre>curl -X PUT &quot;localhost:9200/_cluster/settings?pretty&quot; -H &#39;Content-Type: application/json&#39; -d &#39; { &quot;transient&quot;: { &quot;cluster.routing.allocation.disk.watermark.low&quot;: &quot;5gb&quot;, &quot;cluster.routing.allocation.disk.watermark.high&quot;: &quot;3gb&quot;, &quot;cluster.routing.allocation.disk.watermark.flood_stage&quot;: &quot;1gb&quot; } } &#39; # Here the above example works for indexing smaller number of documents/sec in dev or test</pre><h4>Percentage values</h4><pre>curl -X PUT &quot;localhost:9200/_cluster/settings?pretty&quot; -H &#39;Content-Type: application/json&#39; -d &#39; { &quot;transient&quot;: { &quot;cluster.routing.allocation.disk.watermark.low&quot;: &quot;90%&quot;, &quot;cluster.routing.allocation.disk.watermark.high&quot;: &quot;95%&quot;, &quot;cluster.routing.allocation.disk.watermark.flood_stage&quot;: &quot;98%&quot; } } &#39;</pre><blockquote><em>Note: Enable the </em><em>cluster.routing.allocation.disk.threshold_enabled: true, when the cluster is stable and health is green, so the warnings will be thrown based on the disk usage. Disabling leads to stop the elasticsearch cluster.</em></blockquote><p><em>Originally published at </em><a href="https://jinnabalu.tech/elasticsearch-water-mark/"><em>https://jinnabalu.tech</em></a><em> on November 2, 2020.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=2b7049a13272" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Clean Code Collection]]></title>
            <link>https://jinnabaalu.medium.com/clean-code-collection-e13212bb104?source=rss-5c894fbb59cd------2</link>
            <guid isPermaLink="false">https://medium.com/p/e13212bb104</guid>
            <category><![CDATA[solid-principles]]></category>
            <category><![CDATA[clean-code]]></category>
            <category><![CDATA[good-code]]></category>
            <category><![CDATA[robert-c-martin]]></category>
            <category><![CDATA[bad-code]]></category>
            <dc:creator><![CDATA[Jinna Baalu]]></dc:creator>
            <pubDate>Sun, 09 Aug 2020 17:09:41 GMT</pubDate>
            <atom:updated>2021-02-28T18:43:23.441Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/788/0*aWEBcuJdsNvJssdi.jpg" /><figcaption>Clean Code</figcaption></figure><h3>Clean Code — SOLID Principles</h3><p><a href="http://www.cleancoder.com/products">Robert Cecil Martin is also known as Uncle Bob Martin — SOLID</a></p><p><a href="https://gist.github.com/wojteklu/73c6914cc446146b8b533c0988cf8d29">Summary of ‘Clean code’ by Robert C. Martin</a></p><p><a href="https://www.investigatii.md/uploads/resurse/Clean_Code.pdf">Clean Code PDF</a></p><p><a href="https://github.com/leonardolemie/clean-code-java">Clean Code Java</a></p><p><a href="https://www.baeldung.com/solid-principles">SOLID Java Examples</a></p><p><a href="https://github.com/ryanmcdermott/clean-code-javascript">Clean Code Javascript</a></p><p><a href="https://github.com/labs42io/clean-code-typescript">Clean Code Typescript</a></p><p><a href="https://github.com/thangchung/clean-code-dotnet">Clean Code .Net</a></p><p><a href="https://github.com/uohzxela/clean-code-ruby">Clean Code Ruby</a></p><p><a href="https://github.com/abiodunjames/Awesome-Clean-Code-Resources">Clean Code All Resources</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=e13212bb104" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Simulate Cassandra Scenarios]]></title>
            <link>https://jinnabaalu.medium.com/simulate-cassandra-scenarios-a4fc7bf4aa39?source=rss-5c894fbb59cd------2</link>
            <guid isPermaLink="false">https://medium.com/p/a4fc7bf4aa39</guid>
            <category><![CDATA[multinode-cluster]]></category>
            <category><![CDATA[quorum]]></category>
            <category><![CDATA[high-availability]]></category>
            <category><![CDATA[consistency]]></category>
            <category><![CDATA[cassandra]]></category>
            <dc:creator><![CDATA[Jinna Baalu]]></dc:creator>
            <pubDate>Sun, 09 Aug 2020 16:52:14 GMT</pubDate>
            <atom:updated>2020-08-09T16:57:33.131Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*oYjzipkrFa99-_hb.png" /><figcaption>Cassandra High Available Key-value store | multinode cluster</figcaption></figure><p>Below are the few queries which we search on the internet related to Cassandra, can be answered with a link below</p><ul><li>Data loss in Cassandra</li><li>Quorum Consistency in Cassandra</li><li>How to define read and write consistency in Cassandra</li><li>How to illustrate Quorum Formula&#39;s example with calculating quorum is `<em>N / 2 + 1`</em> where N is the sum of replication factors in each data center.</li><li>Archive high availability with Cassandra</li><li>Tuning Cassandra consistency</li><li>Distribution of data in Cassandra based on number of nodes and replication factor of the keyspace in a datacenter</li><li>Cassandra replication factor vs consistency level</li><li>Multinode cluster configuration in Cassandra</li><li>4 Node Cluster setup in Cassandra</li><li>And so on…</li></ul><p>All the above searches on the internet can be answered with the following link. I must the guy who wrote this formula.</p><p><a href="https://www.ecyrd.com/cassandracalculator/">Cassandra Parameters for Dummies</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a4fc7bf4aa39" width="1" height="1" alt="">]]></content:encoded>
        </item>
    </channel>
</rss>